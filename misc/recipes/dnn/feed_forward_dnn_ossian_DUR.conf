[DEFAULT]

## The DEFAULT section just gives a few global variables -- this is designed to reduce the
## number of paths you have to change when modifying this config file.

##!!! Change the following line to the top level of your copy of the Ossian code:
OSSIAN: /afs/inf.ed.ac.uk/user/o/owatts/sim2/oliver/temp/ossian_msc_2016_test/Ossian 

##!!! Change this to point to the language/data/recipe combination you are working on:
TOP: %(OSSIAN)s/train/rm/speakers/rss_toy_demo/msc_demo_02/


WORKDIR: %(TOP)s/dnn_training_DUR/
DATADIR: %(TOP)s/




[Paths]

work: %(WORKDIR)s/
data: %(DATADIR)s/

plot: %(WORKDIR)s/plots


file_id_list: %(TOP)s/filelist.txt

log_config_file: %(OSSIAN)s/tools/dnn_tts/recipes/general_config/logging_config.conf 
log_file: %(WORKDIR)s/log/log.txt
log_path: %(WORKDIR)s/log/

## You won't need these -- just leave the placeholder paths here:
sptk     :   /this/path/does/not/exist
straight :   /this/path/does/not/exist


in_dur_dir: %(DATADIR)s/dur






[Labels]

label_style: HTS_duration
question_file_name  : %(TOP)s/questions_dur.hed.cont
silence_pattern: ['*/THIS-STRING-DOESNT-APPEAR-IN-LABELS/*'] 
label_align: %(TOP)s/lab_dur

[Extensions]

lab_ext: .lab_dur
dur_ext: .dur

[Outputs]
## This says that we are predicting 5 state durations per example (letter/phone)
dur    : 5


[Waveform]

## This won't be used -- but keep it here as a placeholder:
vocoder_type : WORLD
framelength : 2048

[Architecture]

## Adjust the number and size of hidden layers here:
hidden_layer_size  : [512, 512, 512]
hidden_layer_type  : ['TANH', 'TANH', 'TANH']


## if RNN or sequential training is used, please set sequential_training to True. For 
## use with Ossian, we will only train DNNs, so don't alter this.
sequential_training : False

## You might want to experiment with different learning rates, batch sizes, and maximum 
## number of training epochs:
learning_rate    : 0.002
batch_size       : 256
training_epochs  : 100
warmup_epoch     : 100

L1_regularization: 0.0
L2_regularization: 0.0
hidden_activation: tanh
output_activation: linear
warmup_momentum  : 0.0
private_l2_reg   : 0.0

[Streams]
# which feature to be used in the output
output_features      : ['dur']


[Data]
##!!! You need to divide the files available up into train/validation/test data. We don't need 
##!!! to do any testing, but set test_file_number to 1 to keep the tools happy. Split the remaining
##!!! files between train and validation. Using about 5% or 10% of the data for validation is 
##!!! pretty standard. This is how you might divide up 28 files:
train_file_number: 24
valid_file_number: 3
test_file_number : 1
#buffer size of each block of data to
buffer_size: 200000

[Utility]

plot : True

[Processes]
## For use with Ossian, just keep the first 4 set to True -- we will generate speech later 
## within Ossian itself. You can run each of the 4 steps individually if you like:
NORMLAB  : True
MAKECMP  : True
NORMCMP  : True
TRAINDNN : True
DNNGEN   : False
GENWAV   : False
CALMCD   : False


