[DEFAULT]

## The DEFAULT section just gives a few global variables -- this is designed to reduce the
## number of paths you have to change when modifying this config file.

##!!! Change the following line to the top level of your copy of the Ossian code:
OSSIAN: /afs/inf.ed.ac.uk/user/o/owatts/sim2/oliver/temp/ossian_msc_2016_test/Ossian 

##!!! Change this to point to the language/data/recipe combination you are working on:
TOP: %(OSSIAN)s/train/rm/speakers/rss_toy_demo/msc_demo_02/


WORKDIR: %(TOP)s/dnn_training_ACOUST/
DATADIR: %(TOP)s/dnn_streams/




[Paths]

work: %(WORKDIR)s/
data: %(DATADIR)s/

plot: %(WORKDIR)s/plots


file_id_list: %(TOP)s/filelist.txt

log_config_file: %(OSSIAN)s/tools/dnn_tts/recipes/general_config/logging_config.conf 
log_file: %(WORKDIR)s/log/log.txt
log_path: %(WORKDIR)s/log/

## You won't need these -- just leave the placeholder paths here:
sptk     :   /this/path/does/not/exist
straight :   /this/path/does/not/exist

in_mgc_dir: %(DATADIR)s/mgc
in_lf0_dir: %(DATADIR)s/lf0
in_bap_dir: %(DATADIR)s/bap






[Labels]

question_file_name  : %(TOP)s/questions_dnn.hed.cont
silence_pattern: ['*/3:sil/*'] 
label_align: %(TOP)s/dnn_lab

[Extensions]

lab_ext: .dnn_lab
mgc_ext: .mgc
bap_ext: .bap
lf0_ext: .lf0

[Outputs]
##!!! mgc, bap and lf0 need to be the same sizes as the static streams used when calling
##!!! split_cmp.py previously; the corresponding variables starting d* are just the static
##!!! value multiplied by 3: 
mgc    : 60
dmgc   : 180
bap    : 5
dbap   : 15
lf0    : 1
dlf0   : 3


[Waveform]

## This won't be used -- but keep it here as a placeholder:
vocoder_type : WORLD
framelength : 2048

[Architecture]

## Adjust the number and size of hidden layers here:

hidden_layer_size  : [1024, 1024, 1024, 1024, 1024, 1024]
hidden_layer_type  : ['TANH', 'TANH', 'TANH', 'TANH', 'TANH', 'TANH']

## if RNN or sequential training is used, please set sequential_training to True. For 
## use with Ossian, we will only train DNNs, so don't alter this.
sequential_training : False

## You might want to experiment with different learning rates, batch sizes, and maximum 
## number of training epochs:
learning_rate    : 0.002
batch_size       : 256
training_epochs  : 20
warmup_epoch     : 20

L1_regularization: 0.0
L2_regularization: 0.0
hidden_activation: tanh
output_activation: linear
warmup_momentum  : 0.0
private_l2_reg   : 0.0

[Streams]
# which feature to be used in the output
output_features      : ['mgc', 'lf0', 'vuv', 'bap']

## 144 5 1
[Data]
##!!! You need to divide the files available up into train/validation/test data. We don't need 
##!!! to do any testing, but set test_file_number to 1 to keep the tools happy. Split the remaining
##!!! files between train and validation. Using about 5% or 10% of the data for validation is 
##!!! pretty standard. This is how you might divide up 28 files:
train_file_number: 24
valid_file_number: 3
test_file_number : 1
#buffer size of each block of data to
buffer_size: 100000

[Utility]

plot : True

[Processes]
## For use with Ossian, just keep the first 4 set to True -- we will generate speech later 
## within Ossian itself. You can run each of the 4 steps individually if you like:
NORMLAB  : True
MAKECMP  : True
NORMCMP  : True
TRAINDNN : True
DNNGEN   : False
GENWAV   : False
CALMCD   : False


